{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while reading health_expenditure.csv: ',' expected after '\"'\n",
      "Loaded with relaxed parsing rules.\n",
      "Health Expenditure Columns: ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', 'Unnamed: 68']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 205\u001b[0m\n\u001b[0;32m    203\u001b[0m air_pollution_death, transportation, health_expenditure \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m    204\u001b[0m df \u001b[38;5;241m=\u001b[39m preprocess_data(air_pollution_death, transportation, health_expenditure)\n\u001b[1;32m--> 205\u001b[0m model, X_train_val, X_test, y_train_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m generate_beeswarm_plot(model, X_train_val)\n\u001b[0;32m    207\u001b[0m generate_html(df)\n",
      "Cell \u001b[1;32mIn[6], line 157\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    154\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\n\u001b[0;32m    155\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAir Pollution Deaths\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m X_train_val, X_test, y_train_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m    160\u001b[0m X_train_val \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train_val)\n",
      "File \u001b[1;32mc:\\Users\\Bluewind\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Bluewind\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bluewind\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2485\u001b[0m     )\n\u001b[0;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def define_files():\n",
    "    files = {\n",
    "        \"air_pollution_death\": \"data/air_pollution_death.csv\",\n",
    "        \"transportation\": \"data/road-transportation_country_emissions.csv\",\n",
    "        \"coal\": \"data/coal-mining_country_emissions.csv\",\n",
    "        \"cropland\": \"data/cropland-fires_country_emissions.csv\",\n",
    "        \"residential_commercial\": \"data/residential-and-commercial-onsite-fuel-usage_country_emissions.csv\",\n",
    "        \"forest_clearing\": \"data/forest-land-clearing_country_emissions.csv\",\n",
    "        \"petrochemicals\": \"data/petrochemicals_country_emissions.csv\",\n",
    "        \"electricity_generation\": \"data/electricity-generation_country_emissions.csv\",\n",
    "        \"incineration_open_burning\": \"data/incineration-and-open-burning-of-waste_country_emissions.csv\",\n",
    "        \"health_expenditure\": \"data/health-expenditure.csv\",\n",
    "        \"urban_population\": \"data/urban-population.csv\"\n",
    "    }\n",
    "    return files\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Load datasets with adjusted parameters for health_expenditure\n",
    "def load_data():\n",
    "    import csv\n",
    "    \n",
    "    files = define_files()\n",
    "    air_pollution_death = pd.read_csv(files['air_pollution_death'])\n",
    "    transportation = pd.read_csv(files['transportation'])\n",
    "    \n",
    "    health_expenditure = None  # Initialize to avoid UnboundLocalError\n",
    "    \n",
    "    try:\n",
    "        health_expenditure = pd.read_csv(\n",
    "            files['health_expenditure'], \n",
    "            skiprows=3, \n",
    "            engine='python',\n",
    "            sep=',',\n",
    "            quotechar='\"',\n",
    "            skipinitialspace=True,\n",
    "            on_bad_lines='warn',  # Warn instead of skipping silently\n",
    "            quoting=csv.QUOTE_MINIMAL  # Standard CSV quoting\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while reading health_expenditure.csv: {e}\")\n",
    "        \n",
    "        # Read the file line-by-line to identify the problematic row\n",
    "        with open(files['health_expenditure'], 'r', encoding='utf-8') as file:\n",
    "            for i, line in enumerate(file, 1):\n",
    "                if '\"' in line and line.count('\"') % 2 != 0:  # Unmatched quotes\n",
    "                    print(f\"Issue found on line {i}: {line.strip()}\")\n",
    "        \n",
    "        # Attempt to load again with relaxed CSV parsing\n",
    "        try:\n",
    "            health_expenditure = pd.read_csv(\n",
    "                files['health_expenditure'],\n",
    "                skiprows=3,\n",
    "                engine='python',\n",
    "                sep=',',\n",
    "                quotechar='\"',\n",
    "                skipinitialspace=True,\n",
    "                on_bad_lines='skip',\n",
    "                quoting=csv.QUOTE_NONE,  # Ignore quote issues\n",
    "                escapechar='\\\\'\n",
    "            )\n",
    "            print(\"Loaded with relaxed parsing rules.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed again after relaxing CSV rules: {e2}\")\n",
    "            return air_pollution_death, transportation, None  # Gracefully handle failure\n",
    "\n",
    "    if health_expenditure is not None:\n",
    "        # Clean column names\n",
    "        health_expenditure.columns = health_expenditure.columns.str.replace('\"', '').str.strip()\n",
    "\n",
    "    return air_pollution_death, transportation, health_expenditure\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_data(air_pollution_death, transportation, health_expenditure):\n",
    "    # Clean column names\n",
    "    air_pollution_death.columns = air_pollution_death.columns.str.strip()\n",
    "    transportation.columns = transportation.columns.str.strip()\n",
    "    health_expenditure.columns = health_expenditure.columns.str.strip()\n",
    "    \n",
    "    # Check available columns\n",
    "    print(\"Health Expenditure Columns:\", health_expenditure.columns.tolist())\n",
    "    \n",
    "    # Identify common countries\n",
    "    common_countries = set(air_pollution_death['SpatialDimValueCode']).intersection(\n",
    "        transportation['iso3_country'], health_expenditure['Country Code']\n",
    "    )\n",
    "    print(f\"Common countries found: {len(common_countries)}\")\n",
    "\n",
    "    if not common_countries:\n",
    "        raise ValueError(\"No common countries found across datasets. Check for mismatched country codes.\")\n",
    "    \n",
    "    # Filter datasets\n",
    "    df = air_pollution_death.merge(transportation, left_on='SpatialDimValueCode', right_on='iso3_country') \\\n",
    "                             .merge(health_expenditure, left_on='SpatialDimValueCode', right_on='Country Code')\n",
    "\n",
    "    # Check dataset size after merging\n",
    "    print(f\"Dataset size after merging: {df.shape}\")\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Merged DataFrame is empty. Check data consistency across datasets.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Model training and evaluation\n",
    "def train_model(df):\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Cannot train model on an empty DataFrame.\")\n",
    "    \n",
    "    X = df.drop(['SpatialDimValueCode', 'Air Pollution Deaths'], axis=1)\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    y = df['Air Pollution Deaths'].astype(float)\n",
    "\n",
    "    print(f\"Training samples: {X.shape[0]}\")\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_seed\n",
    "    )\n",
    "    # Drop the key columns and the target column, then select only numeric features.\n",
    "    X = df.drop(['SpatialDimValueCode', 'Air Pollution Deaths'], axis=1)\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    y = df['Air Pollution Deaths'].astype(float)\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_val = scaler.fit_transform(X_train_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=random_seed,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train_val, y_train_val)\n",
    "    y_pred_train = xgb_model.predict(X_train_val)\n",
    "    y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "    train_r2 = r2_score(y_train_val, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f'Train R^2 Score: {train_r2}')\n",
    "    print(f'Test R^2 Score: {test_r2}')\n",
    "\n",
    "    return xgb_model, X_train_val, X_test, y_train_val, y_test\n",
    "\n",
    "# SHAP beeswarm plot\n",
    "def generate_beeswarm_plot(model, X_train_val):\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_train_val)\n",
    "    shap.summary_plot(shap_values, X_train_val, plot_type=\"bee swarm\")\n",
    "    plt.savefig(\"beeswarm_plot.png\", bbox_inches='tight')\n",
    "\n",
    "# HTML generation\n",
    "def generate_html(df):\n",
    "    fig = px.scatter(df, x='Transportation Emissions', y='Air Pollution Deaths', color='SpatialDimValueCode')\n",
    "    fig.write_html('scatter_plot.html')\n",
    "    fig_choropleth = px.choropleth(df, locations='SpatialDimValueCode', color='Air Pollution Deaths',\n",
    "                                   hover_name='SpatialDimValueCode', hover_data=['Air Pollution Deaths'])\n",
    "    fig_choropleth.write_html('choropleth_map.html')\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    air_pollution_death, transportation, health_expenditure = load_data()\n",
    "    df = preprocess_data(air_pollution_death, transportation, health_expenditure)\n",
    "    model, X_train_val, X_test, y_train_val, y_test = train_model(df)\n",
    "    generate_beeswarm_plot(model, X_train_val)\n",
    "    generate_html(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
