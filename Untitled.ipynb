{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15ad8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "def define_files():\n",
    "    files = {\n",
    "        \"air_pollution_death\": \"data/air_pollution_death.csv\",\n",
    "        \"transportation\": 'data/road-transportation_country_emissions.csv',\n",
    "        \"coal\": 'data/coal-mining_country_emissions.csv',\n",
    "        \"cropland\": 'data/cropland-fires_country_emissions.csv',\n",
    "        \"residential_commercial\": 'data/residential-and-commercial-onsite-fuel-usage_country_emissions.csv',\n",
    "        \"forest_clearing\": 'data/forest-land-clearing_country_emissions.csv',\n",
    "        \"petrochemicals\": 'data/petrochemicals_country_emissions.csv',\n",
    "        \"electricity_generation\": 'data/electricity-generation_country_emissions.csv',\n",
    "        \"incineration_open_burning\": 'data/incineration-and-open-burning-of-waste_country_emissions.csv',\n",
    "        \"health_expenditure\": 'data/health-expenditure.csv',\n",
    "        \"urban_population\": 'data/urban-population.csv'\n",
    "    }\n",
    "    return files\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Removes quotes and trims spaces from column names.\"\"\"\n",
    "    df.columns = df.columns.str.replace('\"', '', regex=False).str.replace(\"'\", \"\", regex=False).str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "871bcc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_country_codes(files, env_factors, socio_factors, air_pollution_file):\n",
    "    env_country_codes = set()\n",
    "    socio_country_codes = set()\n",
    "    air_pollution_country_codes = set()\n",
    "\n",
    "    # Extract unique country codes from environmental factors (using 'iso3_country')\n",
    "    for factor in env_factors:\n",
    "        try:\n",
    "            df = pd.read_csv(files[factor], on_bad_lines='skip')\n",
    "            df = clean_column_names(df)\n",
    "\n",
    "            if \"iso3_country\" in df.columns:\n",
    "                env_country_codes.update(df[\"iso3_country\"].dropna().unique())\n",
    "            else:\n",
    "                print(f\"WARNING: 'iso3_country' column not found in {factor} dataset!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {factor}: {e}\")\n",
    "\n",
    "    # Extract unique country codes from socio-economic factors (using 'Country Code')\n",
    "    for factor in socio_factors:\n",
    "        try:\n",
    "            skip_rows = 3  # Skip metadata rows\n",
    "            df = pd.read_csv(files[factor], skiprows=skip_rows, on_bad_lines='skip')\n",
    "            df = clean_column_names(df)\n",
    "\n",
    "            if \"Country Code\" in df.columns:\n",
    "                socio_country_codes.update(df[\"Country Code\"].dropna().unique())\n",
    "            else:\n",
    "                print(f\"WARNING: 'Country Code' column not found in {factor} dataset!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {factor}: {e}\")\n",
    "\n",
    "    # Extract unique country codes from air pollution data (using 'SpatialDimValueCode')\n",
    "    try:\n",
    "        df = pd.read_csv(files[air_pollution_file], on_bad_lines='skip')\n",
    "        df = clean_column_names(df)\n",
    "\n",
    "        if \"SpatialDimValueCode\" in df.columns:\n",
    "            air_pollution_country_codes.update(df[\"SpatialDimValueCode\"].dropna().unique())\n",
    "        else:\n",
    "            print(f\"WARNING: 'SpatialDimValueCode' column not found in {air_pollution_file} dataset!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {air_pollution_file}: {e}\")\n",
    "\n",
    "    # Find the common country codes across all datasets\n",
    "    common_country_codes = sorted(\n",
    "        env_country_codes.intersection(socio_country_codes).intersection(air_pollution_country_codes)\n",
    "    )\n",
    "\n",
    "    print(f\"Common Country Codes Found: {common_country_codes}\")\n",
    "    return common_country_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ce11257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_data(files, common_country_codes):\n",
    "    air_pollution_df = pd.read_csv(files[\"air_pollution_death\"], on_bad_lines='skip')\n",
    "    air_pollution_df = clean_column_names(air_pollution_df)\n",
    "\n",
    "    if \"SpatialDimValueCode\" not in air_pollution_df.columns:\n",
    "        print(\"ERROR: 'SpatialDimValueCode' column missing in air_pollution_death dataset!\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Filter data for common country codes and 2018\n",
    "    air_pollution_df = air_pollution_df[(\n",
    "        air_pollution_df[\"SpatialDimValueCode\"].isin(common_country_codes)) & \n",
    "        (air_pollution_df[\"Period\"] == 2018) & \n",
    "        (air_pollution_df[\"Dim1\"] == \"Both sexes\")\n",
    "    ]\n",
    "    \n",
    "    env_data = {}\n",
    "    environment_factor_files_list = [\n",
    "        'transportation', 'coal', 'cropland', 'residential_commercial', \n",
    "        'forest_clearing', 'petrochemicals', 'electricity_generation', \n",
    "        'incineration_open_burning'\n",
    "    ]\n",
    "\n",
    "    for factor in environment_factor_files_list:\n",
    "        df = pd.read_csv(files[factor], on_bad_lines='skip')\n",
    "        df = clean_column_names(df)\n",
    "        if \"iso3_country\" in df.columns:\n",
    "            df = df[df[\"iso3_country\"].isin(common_country_codes)]\n",
    "        else:\n",
    "            print(f\"WARNING: 'iso3_country' not found in {factor} dataset!\")\n",
    "        env_data[factor] = df\n",
    "    \n",
    "    socio_data = {}\n",
    "    socioeconomic_files_list = ['health_expenditure', 'urban_population']\n",
    "    \n",
    "    for factor in socioeconomic_files_list:\n",
    "        skip_rows = 3  # Skip metadata rows\n",
    "        df = pd.read_csv(files[factor], skiprows=skip_rows, on_bad_lines='skip')\n",
    "        df = clean_column_names(df)\n",
    "        if \"Country Code\" in df.columns:\n",
    "            df = df[df[\"Country Code\"].isin(common_country_codes)]\n",
    "        else:\n",
    "            print(f\"WARNING: 'Country Code' not found in {factor} dataset!\")\n",
    "        socio_data[factor] = df\n",
    "    \n",
    "    return air_pollution_df, env_data, socio_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e86e8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_data(air_pollution_df, env_data, socio_data):\n",
    "    merged_df = air_pollution_df.copy()\n",
    "\n",
    "    for factor, df in env_data.items():\n",
    "        if \"iso3_country\" in df.columns and \"Value\" in df.columns:\n",
    "            merged_df = pd.merge(merged_df, df[['iso3_country', 'Value']], on='iso3_country', how='outer')\n",
    "\n",
    "    for factor, df in socio_data.items():\n",
    "        if \"Country Code\" in df.columns and \"Value\" in df.columns:\n",
    "            merged_df = pd.merge(merged_df, df[['Country Code', 'Value']], on='Country Code', how='outer')\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c5dd12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_environment_and_socioeconomic_data(env_data, socio_data, common_country_codes):\n",
    "    environment_results = []\n",
    "    socioeconomic_results = []\n",
    "\n",
    "    # **(B) Processing Environment Data**\n",
    "    for factor, df in env_data.items():\n",
    "        if \"iso3_country\" in df.columns and \"start_time\" in df.columns and \"emissions_quantity\" in df.columns:\n",
    "            try:\n",
    "                df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\")  # Ensure proper date format\n",
    "                df_filtered = df[(\n",
    "                    df[\"iso3_country\"].isin(common_country_codes)) & \n",
    "                    (df[\"start_time\"] >= \"2018-01-01\")\n",
    "                ]\n",
    "                df_grouped = df_filtered.groupby(\"iso3_country\", as_index=False)[\"emissions_quantity\"].sum()\n",
    "                df_grouped.rename(columns={\"iso3_country\": \"Country Code\", \"emissions_quantity\": factor}, inplace=True)\n",
    "                environment_results.append(df_grouped)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {factor}: {e}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Missing required columns in {factor} dataset!\")\n",
    "\n",
    "    # **(C) Processing Socioeconomic Data**\n",
    "    for factor, df in socio_data.items():\n",
    "        if \"Country Code\" in df.columns and \"2018\" in df.columns:\n",
    "            try:\n",
    "                df_filtered = df[df[\"Country Code\"].isin(common_country_codes)][[\"Country Code\", \"2018\"]]\n",
    "                df_filtered.rename(columns={\"2018\": factor}, inplace=True)\n",
    "                socioeconomic_results.append(df_filtered)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {factor}: {e}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Missing required columns in {factor} dataset!\")\n",
    "\n",
    "    return environment_results, socioeconomic_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce3c50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_environment_socioeconomic_air_pollution_data(environment_results, socioeconomic_results, air_pollution_df):\n",
    "    # **(A) Merge environment_data and socioeconomic_data on common country codes**\n",
    "    # environment_data_combined = pd.concat(environment_results, ignore_index=True)\n",
    "    # socioeconomic_data_combined = pd.concat(socioeconomic_results, ignore_index=True)\n",
    "\n",
    "    environment_data_combined = environment_results[0]\n",
    "    for i in environment_results[1:]:\n",
    "        environment_data_combined = pd.merge(environment_data_combined,i,on=\"Country Code\", how=\"outer\")\n",
    "    \n",
    "    merge_final = environment_data_combined\n",
    "    \n",
    "    for i in socioeconomic_results:\n",
    "        socioeconomic_data_combined = pd.merge(merge_final,i,on=\"Country Code\", how=\"outer\")\n",
    "\n",
    "\n",
    "    # Merge environment and socioeconomic data on 'Country Code'\n",
    "    # merged_env_socio_data = pd.merge(environment_data_combined, socioeconomic_data_combined, on=\"Country Code\", how=\"outer\")\n",
    "    \n",
    "    # **(B) Aggregate air pollution deaths per country**\n",
    "    air_pollution_agg = air_pollution_df.groupby(\"SpatialDimValueCode\", as_index=False)[\"FactValueNumeric\"].sum()\n",
    "    air_pollution_agg.rename(columns={\"SpatialDimValueCode\": \"Country Code\"}, inplace=True)\n",
    "\n",
    "    # **(C) Merge aggregated air pollution data**\n",
    "    merged_data_with_deaths = pd.merge(merge_final, air_pollution_agg, \n",
    "                                       on='Country Code', how='outer')\n",
    "    print(\"merged_data_with_deaths\",merged_data_with_deaths)\n",
    "    # Rename columns to meaningful names\n",
    "    merged_data_with_deaths.rename(columns={\n",
    "        'name_x': 'environmental_value',\n",
    "        'name_y': 'socioeconomic_value',\n",
    "        'Value': 'air_pollution_deaths'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return merged_data_with_deaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "204f543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling start_predict_xgboost()...\n",
      "Defining files...\n",
      "Files defined successfully!\n",
      "Getting common country codes...\n",
      "Common Country Codes Found: ['AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', 'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', 'BRA', 'BRB', 'BRN', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', 'COD', 'COG', 'COL', 'COM', 'CPV', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', 'FRA', 'FSM', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', 'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', 'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KIR', 'KOR', 'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LCA', 'LKA', 'LSO', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', 'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', 'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', 'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', 'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLB', 'SLE', 'SLV', 'SOM', 'SRB', 'SSD', 'STP', 'SUR', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', 'TKM', 'TLS', 'TON', 'TTO', 'TUN', 'TUR', 'TZA', 'UGA', 'UKR', 'URY', 'USA', 'UZB', 'VCT', 'VEN', 'VNM', 'VUT', 'WSM', 'YEM', 'ZAF', 'ZMB', 'ZWE']\n",
      "Loading and filtering data...\n",
      "Processing environment and socioeconomic data...\n",
      "Merging environment, socioeconomic, and air pollution data...\n",
      "merged_data_with_deaths     Country Code  transportation          coal      cropland  \\\n",
      "0            AFG    5.728724e+07  1.237991e+07  3.047164e+07   \n",
      "1            AGO    1.657005e+08  0.000000e+00  7.027087e+07   \n",
      "2            ALB    2.535625e+07  3.709218e+05  1.866232e+06   \n",
      "3            ARE    5.190228e+08  0.000000e+00  1.601377e+05   \n",
      "4            ARG    6.409067e+08  1.997271e+05  7.706948e+08   \n",
      "..           ...             ...           ...           ...   \n",
      "178          WSM    2.020644e+06  0.000000e+00  1.023950e+04   \n",
      "179          YEM    5.327802e+07  0.000000e+00  4.579051e+06   \n",
      "180          ZAF    7.030688e+08  6.454257e+08  2.564283e+08   \n",
      "181          ZMB    7.106907e+07  7.678397e+05  6.251026e+07   \n",
      "182          ZWE    5.908101e+07  1.238390e+07  4.548359e+07   \n",
      "\n",
      "     residential_commercial  forest_clearing  petrochemicals  \\\n",
      "0              8.294334e+06     8.632059e+04    0.000000e+00   \n",
      "1              4.872556e+07     1.024659e+09    0.000000e+00   \n",
      "2              1.147137e+07     4.995076e+06    0.000000e+00   \n",
      "3              9.554346e+06     0.000000e+00    7.280612e+07   \n",
      "4              5.821784e+08     4.487951e+08    1.150682e+07   \n",
      "..                      ...              ...             ...   \n",
      "178            7.913560e+05     0.000000e+00    0.000000e+00   \n",
      "179            4.013655e+07     8.444122e+02    0.000000e+00   \n",
      "180            3.673914e+08     2.595807e+08    2.056768e+07   \n",
      "181            3.337809e+06     5.333158e+08    0.000000e+00   \n",
      "182            9.166988e+06     5.094328e+07    0.000000e+00   \n",
      "\n",
      "     electricity_generation  incineration_open_burning  FactValueNumeric  \n",
      "0              1.929000e+06               6.095110e+05          44151.00  \n",
      "1              3.753900e+07               5.018776e+05          16997.28  \n",
      "2              0.000000e+00               2.078827e+05           6088.43  \n",
      "3              1.217688e+09               1.615316e+06           3599.55  \n",
      "4              7.590450e+08               2.238038e+06          34992.30  \n",
      "..                      ...                        ...               ...  \n",
      "178            1.296000e+06               2.874328e+03             86.13  \n",
      "179            3.254100e+07               8.633200e+04          26334.72  \n",
      "180            3.140103e+09               2.139114e+07          41118.60  \n",
      "181            2.685000e+07               1.808000e+05           7051.77  \n",
      "182            7.680600e+07               2.292942e+05           6990.00  \n",
      "\n",
      "[183 rows x 10 columns]\n",
      "Merged data has 183 rows and 10 columns.\n",
      "    Country Code  transportation          coal      cropland  \\\n",
      "0            AFG    5.728724e+07  1.237991e+07  3.047164e+07   \n",
      "1            AGO    1.657005e+08  0.000000e+00  7.027087e+07   \n",
      "2            ALB    2.535625e+07  3.709218e+05  1.866232e+06   \n",
      "3            ARE    5.190228e+08  0.000000e+00  1.601377e+05   \n",
      "4            ARG    6.409067e+08  1.997271e+05  7.706948e+08   \n",
      "..           ...             ...           ...           ...   \n",
      "178          WSM    2.020644e+06  0.000000e+00  1.023950e+04   \n",
      "179          YEM    5.327802e+07  0.000000e+00  4.579051e+06   \n",
      "180          ZAF    7.030688e+08  6.454257e+08  2.564283e+08   \n",
      "181          ZMB    7.106907e+07  7.678397e+05  6.251026e+07   \n",
      "182          ZWE    5.908101e+07  1.238390e+07  4.548359e+07   \n",
      "\n",
      "     residential_commercial  forest_clearing  petrochemicals  \\\n",
      "0              8.294334e+06     8.632059e+04    0.000000e+00   \n",
      "1              4.872556e+07     1.024659e+09    0.000000e+00   \n",
      "2              1.147137e+07     4.995076e+06    0.000000e+00   \n",
      "3              9.554346e+06     0.000000e+00    7.280612e+07   \n",
      "4              5.821784e+08     4.487951e+08    1.150682e+07   \n",
      "..                      ...              ...             ...   \n",
      "178            7.913560e+05     0.000000e+00    0.000000e+00   \n",
      "179            4.013655e+07     8.444122e+02    0.000000e+00   \n",
      "180            3.673914e+08     2.595807e+08    2.056768e+07   \n",
      "181            3.337809e+06     5.333158e+08    0.000000e+00   \n",
      "182            9.166988e+06     5.094328e+07    0.000000e+00   \n",
      "\n",
      "     electricity_generation  incineration_open_burning  FactValueNumeric  \n",
      "0              1.929000e+06               6.095110e+05          44151.00  \n",
      "1              3.753900e+07               5.018776e+05          16997.28  \n",
      "2              0.000000e+00               2.078827e+05           6088.43  \n",
      "3              1.217688e+09               1.615316e+06           3599.55  \n",
      "4              7.590450e+08               2.238038e+06          34992.30  \n",
      "..                      ...                        ...               ...  \n",
      "178            1.296000e+06               2.874328e+03             86.13  \n",
      "179            3.254100e+07               8.633200e+04          26334.72  \n",
      "180            3.140103e+09               2.139114e+07          41118.60  \n",
      "181            2.685000e+07               1.808000e+05           7051.77  \n",
      "182            7.680600e+07               2.292942e+05           6990.00  \n",
      "\n",
      "[183 rows x 10 columns]\n",
      "merged_data.csv saved successfully!\n",
      "Script execution complete!\n"
     ]
    }
   ],
   "source": [
    "def start_predict_xgboost():\n",
    "    # try:\n",
    "        random_seed = 42\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "\n",
    "        print(\"Defining files...\")\n",
    "        files = define_files()\n",
    "        print(\"Files defined successfully!\")\n",
    "\n",
    "        print(\"Getting common country codes...\")\n",
    "        environment_factor_files_list = [\n",
    "            'transportation', 'coal', 'cropland', 'residential_commercial', \n",
    "            'forest_clearing', 'petrochemicals', 'electricity_generation', \n",
    "            'incineration_open_burning'\n",
    "        ]\n",
    "        socioeconomic_files_list = ['health_expenditure', 'urban_population']\n",
    "        common_country_codes = get_common_country_codes(files, environment_factor_files_list, socioeconomic_files_list, \"air_pollution_death\")\n",
    "\n",
    "        print(\"Loading and filtering data...\")\n",
    "        air_pollution_df, env_data, socio_data = load_and_filter_data(files, common_country_codes)\n",
    "\n",
    "        if air_pollution_df is None:\n",
    "            print(\"ERROR: Data loading failed.\")\n",
    "            return\n",
    "\n",
    "        print(\"Processing environment and socioeconomic data...\")\n",
    "        environment_results, socioeconomic_results = process_environment_and_socioeconomic_data(env_data, socio_data, common_country_codes)\n",
    "\n",
    "        # **Merge environment, socioeconomic, and air pollution data**\n",
    "        print(\"Merging environment, socioeconomic, and air pollution data...\")\n",
    "        merged_data = merge_environment_socioeconomic_air_pollution_data(environment_results, socioeconomic_results, air_pollution_df)\n",
    "        # Rename the columns to more meaningful names\n",
    "        # merged_data.rename(columns={\n",
    "        #     'name_x': 'environmental_value',\n",
    "        #     'name_y': 'socioeconomic_value',\n",
    "        #     'SpatialDimValueCode': 'Country Code',\n",
    "        #     'Value': 'air_pollution_deaths'  # Assuming 'Value' represents the air pollution deaths\n",
    "        # }, inplace=True)\n",
    "\n",
    "        print(f\"Merged data has {merged_data.shape[0]} rows and {merged_data.shape[1]} columns.\")\n",
    "        print(merged_data)  # Optional: Check the first few rows of the merged dataframe\n",
    "\n",
    "        if merged_data is None or merged_data.empty:\n",
    "            print(\"ERROR: merged_data is empty or not defined.\")\n",
    "        else:\n",
    "            merged_data.to_csv(\"merged_data.csv\", index=False)\n",
    "            print(\"merged_data.csv saved successfully!\")\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(\"An error occurred:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Calling start_predict_xgboost()...\")\n",
    "    start_predict_xgboost()\n",
    "    print(\"Script execution complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e2aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
